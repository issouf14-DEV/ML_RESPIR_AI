# models/train_model.py
import pandas as pd
import numpy as np
import joblib
import os
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from tabpfn import TabPFNClassifier
from huggingface_hub import login
import warnings
warnings.filterwarnings('ignore')

# Charger les variables d'environnement depuis .env
try:
    from dotenv import load_dotenv
    # Chercher .env dans le dossier parent (racine du projet)
    env_path = Path(__file__).parent.parent / '.env'
    if env_path.exists():
        load_dotenv(env_path)
        print(f"‚úÖ Variables charg√©es depuis {env_path}")
    else:
        # Chercher aussi dans venv/.env
        env_path_venv = Path(__file__).parent.parent / 'venv' / '.env'
        if env_path_venv.exists():
            load_dotenv(env_path_venv)
            print(f"‚úÖ Variables charg√©es depuis {env_path_venv}")
except ImportError:
    print("‚ö†Ô∏è python-dotenv non install√©, utilisation des variables syst√®me")

# Configuration des chemins
BASE_DIR = Path(__file__).parent.parent
DATA_DIR = BASE_DIR / 'data'
MODEL_DIR = BASE_DIR / 'models'

# Token HuggingFace depuis variable d'environnement
HF_TOKEN = os.environ.get("HF_TOKEN")
if not HF_TOKEN or HF_TOKEN == "YOUR_HUGGINGFACE_TOKEN":
    print("‚ö†Ô∏è HF_TOKEN non d√©fini! D√©finissez-le dans .env ou comme variable d'environnement")

def train_respiria_model():
    """Entra√Æne le mod√®le Respiria avec TabPFN"""
    
    print("="*70)
    print("üöÄ ENTRA√éNEMENT DU MOD√àLE RESPIRIA ML")
    print("="*70)
    
    # 1. Connexion HuggingFace
    print("\n1Ô∏è‚É£ Connexion √† HuggingFace...")
    if 'HF_TOKEN' in os.environ:
        del os.environ['HF_TOKEN']
    login(token=HF_TOKEN)
    print("‚úÖ Connect√©")
    
    # 2. Chargement du dataset
    print("\n2Ô∏è‚É£ Chargement du dataset...")
    dataset_path = DATA_DIR / 'respiria_dataset.csv'
    
    if not dataset_path.exists():
        print(f"‚ùå Fichier non trouv√© : {dataset_path}")
        print(f"üìÅ Cherche dans : {DATA_DIR}")
        print(f"üìÇ Fichiers disponibles : {list(DATA_DIR.glob('*.csv'))}")
        return None, None
    
    df = pd.read_csv(dataset_path)
    print(f"‚úÖ {len(df)} √©chantillons charg√©s")
    print(f"üìä Shape : {df.shape}")
    
    # 3. Feature Engineering
    print("\n3Ô∏è‚É£ Feature Engineering...")
    X = df.drop('risk_class', axis=1)
    y = df['risk_class']
    
    # Interactions profil √ó capteurs (crucial pour diff√©rencier les profils)
    X['profile_x_hr'] = X['heart_rate_bpm'] * X['user_profile']
    X['profile_x_spo2'] = X['spo2'] * X['user_profile']
    X['profile_x_eco2'] = X['eco2_ppm'] * X['user_profile']
    X['profile_x_aqi'] = X['aqi'] * X['user_profile']
    
    print(f"‚úÖ {X.shape[1]} features cr√©√©es")
    print(f"üìã Features : {list(X.columns)}")
    
    # 4. Normalisation
    print("\n4Ô∏è‚É£ Normalisation...")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    X_scaled = pd.DataFrame(X_scaled, columns=X.columns)
    print("‚úÖ Normalisation termin√©e")
    
    # 5. Split
    print("\n5Ô∏è‚É£ Train/Test split...")
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42, stratify=y
    )
    print(f"‚úÖ Train: {len(X_train)} | Test: {len(X_test)}")
    
    # 6. Sous-√©chantillonnage pour TabPFN
    print("\n6Ô∏è‚É£ Pr√©paration pour TabPFN...")
    sample_size = min(1000, len(X_train))
    X_train_sample, _, y_train_sample, _ = train_test_split(
        X_train, y_train,
        train_size=sample_size,
        stratify=y_train,
        random_state=42
    )
    print(f"‚úÖ {len(X_train_sample)} √©chantillons pour l'entra√Ænement")
    
    # 7. Entra√Ænement
    print("\n7Ô∏è‚É£ Entra√Ænement TabPFN...")
    print("‚è≥ Cela prend 2-5 minutes...")
    
    model = TabPFNClassifier(
        device="cpu",
        n_estimators=32,
        ignore_pretraining_limits=True
    )
    
    model.fit(X_train_sample, y_train_sample)
    print("‚úÖ Mod√®le entra√Æn√© !")
    
    # 8. √âvaluation
    print("\n8Ô∏è‚É£ √âvaluation...")
    y_pred = model.predict(X_test)
    
    print("\n" + "="*70)
    print("üìä RAPPORT DE CLASSIFICATION")
    print("="*70)
    report = classification_report(
        y_test, y_pred,
        target_names=['Risque faible', 'Risque mod√©r√©', 'Risque √©lev√©'],
        digits=3
    )
    print(report)
    
    # Matrice de confusion
    cm = confusion_matrix(y_test, y_pred)
    print("\nüìä MATRICE DE CONFUSION")
    print(cm)
    
    # 9. Sauvegarde
    print("\n9Ô∏è‚É£ Sauvegarde...")
    
    # Cr√©er le dossier models s'il n'existe pas
    MODEL_DIR.mkdir(exist_ok=True)
    
    joblib.dump(model, MODEL_DIR / 'respiria_model.pkl')
    joblib.dump(scaler, MODEL_DIR / 'respiria_scaler.pkl')
    joblib.dump(list(X.columns), MODEL_DIR / 'respiria_features.pkl')
    
    print(f"‚úÖ Mod√®le sauvegard√© : {MODEL_DIR / 'respiria_model.pkl'}")
    print(f"‚úÖ Scaler sauvegard√© : {MODEL_DIR / 'respiria_scaler.pkl'}")
    print(f"‚úÖ Features sauvegard√©es : {MODEL_DIR / 'respiria_features.pkl'}")
    
    # 10. Test rapide
    print("\nüîü Test rapide du mod√®le...")
    test_data = pd.DataFrame([{
        'user_profile': 1,
        'heart_rate_bpm': 95,
        'spo2': 93,
        'temperature_c': 26,
        'humidity_percent': 65,
        'eco2_ppm': 1100,
        'tvoc_ppb': 500,
        'aqi': 110,
        'pollen_level': 100,
        'profile_x_hr': 95,
        'profile_x_spo2': 93,
        'profile_x_eco2': 1100,
        'profile_x_aqi': 110
    }])
    
    test_scaled = scaler.transform(test_data)
    prediction = model.predict(test_scaled)[0]
    probas = model.predict_proba(test_scaled)[0]
    
    risk_labels = {0: 'Faible', 1: 'Mod√©r√©', 2: '√âlev√©'}
    print(f"   Risque pr√©dit : {risk_labels[prediction]}")
    print(f"   Probabilit√©s : {probas}")
    
    print("\n" + "="*70)
    print("‚úÖ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS")
    print("="*70)
    
    return model, scaler

if __name__ == "__main__":
    model, scaler = train_respiria_model()